{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiser Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this section, we start looking at the [fpgaconvnet-optimiser](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser) which is able to automatically perform Design Space Exploration (DSE) based on the predictions from [fpgaconvnet-model](https://github.com/AlexMontgomerie/fpgaconvnet-model) and identify the optimal acclerator configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the optimiser repository, we introduce `transform`s to manipulate the accelerator configuration to trade resources for better performace:\n",
    "\n",
    "[`partition`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/partition.py), which can split/merge the partitions in a network.\n",
    "\n",
    "[`coarse`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/coarse.py), which controls the number of parallel data stream in/out for a given layer.\n",
    "\n",
    "[`fine`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/fine.py), which changes the parallelism on the kernel dimension of convolutional layers.\n",
    "\n",
    "[`weights_reloading`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/weights_reloading.py), which repeats the computation of a parition but multiplexes different weights, only affecting the last convolutional/fully-connected layer in a parition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see some examples of using these `transform`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL WARNING: node Flatten_31 is skipped in hardware\n",
      "0, resource:  {'FF': 38956, 'LUT': 63555, 'DSP': 17, 'BRAM': 15002, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "from fpgaconvnet.parser.Parser import Parser\n",
    "\n",
    "onnx_path = \"../3.1_model_onnx_parser/fp16/vgg16_bn.onnx\"\n",
    "parser = Parser(custom_onnx=True, batch_size=1)\n",
    "net = parser.onnx_to_fpgaconvnet(onnx_path)\n",
    "\n",
    "for i, partition in enumerate(net.partitions):\n",
    "    print(f\"{i}, resource: \", partition.get_resource_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`split_complete`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/partition.py#L242) function is responsible for generating partitions, each containing a single layer. For a device setup, partitions are scheduled sequentially in a time-multiplexed manner, so the actual resource requirement is significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, resource:  {'FF': 2108, 'LUT': 4206, 'DSP': 1, 'BRAM': 4, 'URAM': 0}\n",
      "1, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "2, resource:  {'FF': 2195, 'LUT': 4197, 'DSP': 1, 'BRAM': 45, 'URAM': 0}\n",
      "3, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "4, resource:  {'FF': 504, 'LUT': 355, 'DSP': 0, 'BRAM': 2, 'URAM': 0}\n",
      "5, resource:  {'FF': 2213, 'LUT': 4287, 'DSP': 1, 'BRAM': 79, 'URAM': 0}\n",
      "6, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "7, resource:  {'FF': 2239, 'LUT': 4287, 'DSP': 1, 'BRAM': 153, 'URAM': 0}\n",
      "8, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "9, resource:  {'FF': 524, 'LUT': 349, 'DSP': 0, 'BRAM': 4, 'URAM': 0}\n",
      "10, resource:  {'FF': 2276, 'LUT': 4465, 'DSP': 1, 'BRAM': 295, 'URAM': 0}\n",
      "11, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "12, resource:  {'FF': 2305, 'LUT': 4465, 'DSP': 1, 'BRAM': 585, 'URAM': 0}\n",
      "13, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "14, resource:  {'FF': 2305, 'LUT': 4465, 'DSP': 1, 'BRAM': 585, 'URAM': 0}\n",
      "15, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "16, resource:  {'FF': 545, 'LUT': 349, 'DSP': 0, 'BRAM': 4, 'URAM': 0}\n",
      "17, resource:  {'FF': 2379, 'LUT': 4821, 'DSP': 1, 'BRAM': 1159, 'URAM': 0}\n",
      "18, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "19, resource:  {'FF': 2416, 'LUT': 4821, 'DSP': 1, 'BRAM': 2314, 'URAM': 0}\n",
      "20, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "21, resource:  {'FF': 2416, 'LUT': 4821, 'DSP': 1, 'BRAM': 2314, 'URAM': 0}\n",
      "22, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "23, resource:  {'FF': 566, 'LUT': 349, 'DSP': 0, 'BRAM': 4, 'URAM': 0}\n",
      "24, resource:  {'FF': 2416, 'LUT': 4821, 'DSP': 1, 'BRAM': 2312, 'URAM': 0}\n",
      "25, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "26, resource:  {'FF': 2416, 'LUT': 4821, 'DSP': 1, 'BRAM': 2312, 'URAM': 0}\n",
      "27, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "28, resource:  {'FF': 2416, 'LUT': 4821, 'DSP': 1, 'BRAM': 2312, 'URAM': 0}\n",
      "29, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "30, resource:  {'FF': 5251, 'LUT': 458, 'DSP': 1, 'BRAM': 0, 'URAM': 0}\n",
      "31, resource:  {'FF': 362, 'LUT': 952, 'DSP': 1, 'BRAM': 257, 'URAM': 0}\n",
      "32, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "33, resource:  {'FF': 362, 'LUT': 952, 'DSP': 1, 'BRAM': 257, 'URAM': 0}\n",
      "34, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "35, resource:  {'FF': 217, 'LUT': 253, 'DSP': 1, 'BRAM': 5, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "import fpgaconvnet.optimiser.transforms as transforms\n",
    "\n",
    "transforms.partition.split_complete(net, None)\n",
    "for i, partition in enumerate(net.partitions):\n",
    "    transforms.weights_reloading.remove_weights_reloading_transform(partition)\n",
    "    partition.update()\n",
    "    print(f\"{i}, resource: \", partition.get_resource_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find the BRAM requirement in some partitions is stll quite high, as we cannot split one layer into multiple partitions. Instead, the [`apply_max_weights_reloading`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/8a2487a2ecf6b59af3352af8ab78a44a1f443f05/fpgaconvnet/optimiser/transforms/weights_reloading.py#L34) function can further reduce the BRAM usage, by only storing the weights of a single filter at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, resource:  {'FF': 2090, 'LUT': 4120, 'DSP': 1, 'BRAM': 1, 'URAM': 0}\n",
      "1, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "2, resource:  {'FF': 2177, 'LUT': 4111, 'DSP': 1, 'BRAM': 9, 'URAM': 0}\n",
      "3, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "4, resource:  {'FF': 504, 'LUT': 355, 'DSP': 0, 'BRAM': 2, 'URAM': 0}\n",
      "5, resource:  {'FF': 2177, 'LUT': 4111, 'DSP': 1, 'BRAM': 7, 'URAM': 0}\n",
      "6, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "7, resource:  {'FF': 2202, 'LUT': 4111, 'DSP': 1, 'BRAM': 10, 'URAM': 0}\n",
      "8, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "9, resource:  {'FF': 524, 'LUT': 349, 'DSP': 0, 'BRAM': 4, 'URAM': 0}\n",
      "10, resource:  {'FF': 2202, 'LUT': 4111, 'DSP': 1, 'BRAM': 8, 'URAM': 0}\n",
      "11, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "12, resource:  {'FF': 2231, 'LUT': 4111, 'DSP': 1, 'BRAM': 11, 'URAM': 0}\n",
      "13, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "14, resource:  {'FF': 2231, 'LUT': 4111, 'DSP': 1, 'BRAM': 11, 'URAM': 0}\n",
      "15, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "16, resource:  {'FF': 545, 'LUT': 349, 'DSP': 0, 'BRAM': 4, 'URAM': 0}\n",
      "17, resource:  {'FF': 2231, 'LUT': 4111, 'DSP': 1, 'BRAM': 9, 'URAM': 0}\n",
      "18, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "19, resource:  {'FF': 2268, 'LUT': 4111, 'DSP': 1, 'BRAM': 14, 'URAM': 0}\n",
      "20, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "21, resource:  {'FF': 2268, 'LUT': 4111, 'DSP': 1, 'BRAM': 14, 'URAM': 0}\n",
      "22, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "23, resource:  {'FF': 566, 'LUT': 349, 'DSP': 0, 'BRAM': 4, 'URAM': 0}\n",
      "24, resource:  {'FF': 2268, 'LUT': 4111, 'DSP': 1, 'BRAM': 12, 'URAM': 0}\n",
      "25, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "26, resource:  {'FF': 2268, 'LUT': 4111, 'DSP': 1, 'BRAM': 12, 'URAM': 0}\n",
      "27, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "28, resource:  {'FF': 2268, 'LUT': 4111, 'DSP': 1, 'BRAM': 12, 'URAM': 0}\n",
      "29, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "30, resource:  {'FF': 5251, 'LUT': 458, 'DSP': 1, 'BRAM': 0, 'URAM': 0}\n",
      "31, resource:  {'FF': 214, 'LUT': 242, 'DSP': 1, 'BRAM': 1, 'URAM': 0}\n",
      "32, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "33, resource:  {'FF': 214, 'LUT': 242, 'DSP': 1, 'BRAM': 1, 'URAM': 0}\n",
      "34, resource:  {'FF': 35, 'LUT': 16, 'DSP': 0, 'BRAM': 0, 'URAM': 0}\n",
      "35, resource:  {'FF': 214, 'LUT': 242, 'DSP': 1, 'BRAM': 1, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, partition in enumerate(net.partitions):\n",
    "    transforms.weights_reloading.apply_max_weights_reloading(partition)\n",
    "    partition.update()\n",
    "    print(f\"{i}, resource: \", partition.get_resource_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying [`split_complete`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/partition.py#L242) and [`apply_max_weights_reloading`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/8a2487a2ecf6b59af3352af8ab78a44a1f443f05/fpgaconvnet/optimiser/transforms/weights_reloading.py#L34), we obtain the accelerator configuratoin that requires minimal resource utilization, which is referred to the \"resource-minimal\" status in the DSE process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse_in:  1\n",
      "coarse_out:  1\n",
      "coarse_group:  1\n",
      "fine:  1\n",
      "Latency (cycle): 27648\n",
      "{'LUT': 4120, 'FF': 2090, 'DSP': 1, 'BRAM': 1, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "conv_0_layer = net.partitions[0].graph.nodes[\"Conv_0\"][\"hw\"]\n",
    "\n",
    "print(\"coarse_in: \", conv_0_layer.coarse_in)\n",
    "print(\"coarse_out: \", conv_0_layer.coarse_out)\n",
    "print(\"coarse_group: \", conv_0_layer.coarse_group)\n",
    "print(\"fine: \", conv_0_layer.fine)\n",
    "print(\"Latency (cycle):\", conv_0_layer.latency())\n",
    "print(conv_0_layer.resource())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`apply_random_coarse_node`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/coarse.py#L20) function randomly modifies the `coarse_in`, `coarse_out` and `coarse_group` attributes of the given layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse_in:  3\n",
      "coarse_out:  1\n",
      "coarse_group:  1\n",
      "fine:  1\n",
      "Latency (cycle): 9216\n",
      "{'LUT': 6748, 'FF': 3303, 'DSP': 3, 'BRAM': 3, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "while conv_0_layer.coarse_in * conv_0_layer.coarse_out * conv_0_layer.coarse_group == 1:\n",
    "    transforms.apply_random_coarse_node(net.partitions[0], \"Conv_0\")\n",
    "    net.partitions[0].update()\n",
    "\n",
    "print(\"coarse_in: \", conv_0_layer.coarse_in)\n",
    "print(\"coarse_out: \", conv_0_layer.coarse_out)\n",
    "print(\"coarse_group: \", conv_0_layer.coarse_group)\n",
    "print(\"fine: \", conv_0_layer.fine)\n",
    "print(\"Latency (cycle):\", conv_0_layer.latency())\n",
    "print(conv_0_layer.resource())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`apply_complete_fine`](https://github.com/AlexMontgomerie/fpgaconvnet-optimiser/blob/dev-petros/fpgaconvnet/optimiser/transforms/fine.py) function maxize the `fine` attribute for all the convolutional layers in the given partition, which is equal to fully unrolling their comutation in the kernel dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse_in:  3\n",
      "coarse_out:  1\n",
      "coarse_group:  1\n",
      "fine:  9\n",
      "Latency (cycle): 1156\n",
      "{'LUT': 2519, 'FF': 3113, 'DSP': 27, 'BRAM': 3, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "transforms.apply_complete_fine(net.partitions[0])\n",
    "net.partitions[0].update()\n",
    "\n",
    "print(\"coarse_in: \", conv_0_layer.coarse_in)\n",
    "print(\"coarse_out: \", conv_0_layer.coarse_out)\n",
    "print(\"coarse_group: \", conv_0_layer.coarse_group)\n",
    "print(\"fine: \", conv_0_layer.fine)\n",
    "print(\"Latency (cycle):\", conv_0_layer.latency())\n",
    "print(conv_0_layer.resource())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe how resource and latency change after these `transform`s applied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
