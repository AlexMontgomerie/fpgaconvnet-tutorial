{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layer Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the `Layer` and `Module` classes instead. `Layer` corresponds to a node in onnx, and when it is implemented on the hardware, it is decomposed into multiple `Module`s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL WARNING: node Flatten_31 is skipped in hardware\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('pad',\n",
       "              Pad(rows=32, cols=32, channels=3, data_width=16, rsc_coef={'FF': [], 'LUT': [], 'DSP': [], 'BRAM': []}, pad_top=1, pad_bottom=1, pad_left=1, pad_right=1, backend='chisel', regression_model='linear_regression', streams=1, latency_mode=False, block=False)),\n",
       "             ('sliding_window',\n",
       "              SlidingWindow(rows=34, cols=34, channels=3, data_width=16, rsc_coef={'Logic_LUT': array([6.46840521, 0.        , 0.        , 3.92659388, 2.45084112]), 'LUT_RAM': array([ 0.07302216,  0.        , 14.23619095]), 'LUT_SR': array([0.]), 'FF': array([ 0.        ,  0.        , 20.77153538,  0.        ,  0.        ,\n",
       "                      0.        ,  5.21236925,  3.44020551,  0.        ,  0.        ]), 'DSP': array([0.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}, kernel_size=[3, 3], stride=[1, 1], pad_top=0, pad_right=0, pad_bottom=0, pad_left=0, backend='chisel', regression_model='linear_regression', streams=1)),\n",
       "             ('squeeze',\n",
       "              Squeeze(rows=32, cols=32, channels=3, data_width=16, rsc_coef={'Logic_LUT': array([  0.        ,   2.22688964,   0.        ,   0.        ,\n",
       "                     235.5859881 ,   0.        ,   3.29301748,   0.        ]), 'LUT_RAM': array([48.82925296]), 'LUT_SR': array([0]), 'FF': array([   0.        ,   15.87391647,    3.48485944,    0.        ,\n",
       "                        5.69486761, 1084.90151568]), 'DSP': array([0]), 'BRAM36': array([0]), 'BRAM18': array([0])}, coarse_in=9, coarse_out=1, backend='chisel', regression_model='linear_regression', streams=1)),\n",
       "             ('fork',\n",
       "              Fork(rows=32, cols=32, channels=3, data_width=16, rsc_coef={'Logic_LUT': array([0.00000000e+00, 5.00000000e-01, 0.00000000e+00, 1.85479216e-18,\n",
       "                     5.00000000e+00]), 'LUT_RAM': array([0.]), 'LUT_SR': array([0.]), 'FF': array([12.,  0.,  3.]), 'DSP': array([0.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}, kernel_size=[1, 1], coarse=1, backend='chisel', regression_model='linear_regression', streams=1)),\n",
       "             ('vector_dot',\n",
       "              VectorDot(rows=32, cols=32, channels=27, data_width=16, rsc_coef={'Logic_LUT': array([2.57125885, 0.        , 0.        , 0.        , 0.        ,\n",
       "                     0.97287269, 0.        , 0.        , 0.        ]), 'LUT_RAM': array([4.52464937, 0.        ]), 'LUT_SR': array([0.16773743]), 'FF': array([ 0.        ,  0.        ,  0.        ,  0.        , 21.36862368,\n",
       "                      1.48600702,  0.18202488,  0.        ]), 'DSP': array([1.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}, filters=64, fine=1, backend='chisel', regression_model='linear_regression', weight_width=16, acc_width=32, streams=1)),\n",
       "             ('accum',\n",
       "              Accum(rows=32, cols=32, channels=27, data_width=32, rsc_coef={'Logic_LUT': array([0.85353288, 0.        , 3.51035984, 0.        , 0.        ,\n",
       "                     0.        , 0.        ]), 'LUT_RAM': array([13.67379136,  0.01678309,  0.92521122,  0.        ]), 'LUT_SR': array([0.]), 'FF': array([0.        , 3.20979382, 0.        , 0.        , 0.00732597,\n",
       "                     0.28885062, 0.        ]), 'DSP': array([0.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}, filters=64, groups=1, skip_all_zero_window=False, sparsity_hist=None, backend='chisel', regression_model='linear_regression', streams=1)),\n",
       "             ('glue',\n",
       "              Glue(rows=32, cols=32, channels=1, data_width=32, rsc_coef={'Logic_LUT': array([1.26165591, 0.        , 0.        , 0.        ]), 'LUT_RAM': array([8.87874832, 0.        ]), 'LUT_SR': array([0.16089866, 0.19529144]), 'FF': array([9.53751151, 0.36080769, 0.        , 0.05106319, 1.0280541 ,\n",
       "                     0.        ]), 'DSP': array([0.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}, filters=64, coarse_in=1, coarse_out=1, coarse_group=1, backend='chisel', regression_model='linear_regression', streams=1)),\n",
       "             ('bias',\n",
       "              Bias(rows=32, cols=32, channels=1, data_width=16, rsc_coef={'Logic_LUT': array([0.8125]), 'LUT_RAM': array([0.]), 'LUT_SR': array([0.]), 'FF': array([2.1875, 0.    , 0.    ]), 'DSP': array([0.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}, filters=64, biases_width=32, backend='chisel', regression_model='linear_regression', streams=1)),\n",
       "             ('shift_scale',\n",
       "              ShiftScale(rows=32, cols=32, channels=1, data_width=16, rsc_coef={'FF': [], 'LUT': [], 'DSP': [], 'BRAM': []}, filters=64, biases_width=32, backend='chisel', regression_model='linear_regression', streams=1))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpgaconvnet.parser.Parser import Parser\n",
    "\n",
    "onnx_path = \"../3.1_model_onnx_parser/fp16/vgg16_bn.onnx\"\n",
    "parser = Parser(custom_onnx=True, batch_size=1)\n",
    "net = parser.onnx_to_fpgaconvnet(onnx_path)\n",
    "conv_0_layer = net.partitions[0].graph.nodes[\"Conv_0\"][\"hw\"]\n",
    "conv_0_layer.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer has a set of tunable design parameters that control the configuration in its modules, by trading resources for improved performance. For example, in a convolutional layer, fpgaConvNet provides `coarse_in`, `coarse_out`, `coarse_group` and `fine` which are design parameters related to the parallelism on the input channel, output channel, groups and kernel size dimensions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse_in:  1\n",
      "coarse_out:  1\n",
      "coarse_group:  1\n",
      "fine:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"coarse_in: \", conv_0_layer.coarse_in)\n",
    "print(\"coarse_out: \", conv_0_layer.coarse_out)\n",
    "print(\"coarse_group: \", conv_0_layer.coarse_group)\n",
    "print(\"fine: \", conv_0_layer.fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, everything happening within the layer is sequential, so their values are all one. To examine the latency and resource utilization of current `conv_0_layer`, we can do this by calling [`resource()`](https://github.com/AlexMontgomerie/fpgaconvnet-model/blob/dev-petros/fpgaconvnet/models/layers/ConvolutionLayer.py#L590) and [`latency()`](https://github.com/AlexMontgomerie/fpgaconvnet-model/blob/dev-petros/fpgaconvnet/models/layers/Layer.py#L305) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency (cycle): 1769472\n",
      "{'LUT': 4206, 'FF': 2108, 'DSP': 1, 'BRAM': 4, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Latency (cycle):\", conv_0_layer.latency())\n",
    "print(conv_0_layer.resource())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the resource prediction, fpgaConvNet uses linear regression to estimate resources at module level. Specifically, each module has the attribute `rsc_coef` that was generated beforehand by running a set of designs through synthesis, and we define the variables that have impact on resources in the `utilisation_model` function. The final resource estimation is obtained by calling the `rsc` function of individual modules (https://github.com/AlexMontgomerie/fpgaconvnet-model/blob/dev-petros/fpgaconvnet/models/modules/Module.py#L111). For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsc_coef:  {'Logic_LUT': array([0.85353288, 0.        , 3.51035984, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'LUT_RAM': array([13.67379136,  0.01678309,  0.92521122,  0.        ]), 'LUT_SR': array([0.]), 'FF': array([0.        , 3.20979382, 0.        , 0.        , 0.00732597,\n",
      "       0.28885062, 0.        ]), 'DSP': array([0.]), 'BRAM36': array([0.]), 'BRAM18': array([0.])}\n",
      "utilisation_model:  {'Logic_LUT': array([64, 27, 32,  1,  5,  6,  1]), 'LUT_RAM': array([   3, 2048,   32,   64]), 'LUT_SR': array([0]), 'FF': array([32, 32,  5,  6, 27, 64,  1]), 'DSP': array([0]), 'BRAM36': array([0]), 'BRAM18': array([0])}\n",
      "accum rsc:  {'Logic_LUT': 166, 'LUT_RAM': 104, 'LUT_SR': 0, 'FF': 121, 'DSP': 0, 'BRAM36': 0, 'BRAM18': 0, 'LUT': 270, 'BRAM': 0}\n"
     ]
    }
   ],
   "source": [
    "accum_module = conv_0_layer.modules[\"accum\"]\n",
    "print(\"rsc_coef: \", accum_module.rsc_coef)\n",
    "print(\"utilisation_model: \", accum_module.utilisation_model())\n",
    "print(\"accum rsc: \",accum_module.rsc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also modify the design paramters of each layer to trade resources for better performance. For example, we can maximize the parallelim of the convolutional layer by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse_in:  3\n",
      "coarse_out:  64\n",
      "coarse_group:  1\n",
      "fine:  9\n",
      "Latency (cycle): 1156\n",
      "{'LUT': 66973, 'FF': 94988, 'DSP': 1728, 'BRAM': 828, 'URAM': 0}\n"
     ]
    }
   ],
   "source": [
    "conv_0_layer.coarse_in = conv_0_layer.get_coarse_in_feasible()[-1]\n",
    "conv_0_layer.coarse_out = conv_0_layer.get_coarse_out_feasible()[-1]\n",
    "conv_0_layer.coarse_group = conv_0_layer.get_coarse_group_feasible()[-1]\n",
    "conv_0_layer.fine = conv_0_layer.get_fine_feasible()[-1]\n",
    "\n",
    "conv_0_layer.update()\n",
    "\n",
    "print(\"coarse_in: \", conv_0_layer.coarse_in)\n",
    "print(\"coarse_out: \", conv_0_layer.coarse_out)\n",
    "print(\"coarse_group: \", conv_0_layer.coarse_group)\n",
    "print(\"fine: \", conv_0_layer.fine)\n",
    "\n",
    "print(\"Latency (cycle):\", conv_0_layer.latency())\n",
    "print(conv_0_layer.resource())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `update` function is to propogate the change from layer to module level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
